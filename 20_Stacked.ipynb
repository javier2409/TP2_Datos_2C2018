{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train y predict set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('features_05.csv')\n",
    "file = file.drop(['primer_visita','ultima_visita'],axis=1)\n",
    "labels = pd.read_csv('labels_training_set.csv')\n",
    "kaggle = pd.read_csv('trocafone_kaggle_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = labels.set_index('person').join(file.set_index('person'),how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training.drop('label',axis=1)\n",
    "training_labels = training['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set = kaggle.set_index('person').join(file.set_index('person'),how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "for index,v in enumerate(training_set.columns):\n",
    "    if training_set[v].dtype.name == 'object':\n",
    "        cat.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat:\n",
    "    training_set[i] = training_set[i].astype('category')\n",
    "    prediction_set[i] = prediction_set[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregarFeatureTrain (dataset,labels,clasif_list,n):\n",
    "    to_return = []\n",
    "    new_dataset = dataset.copy(deep=True)\n",
    "    kf = KFold(n_splits=n)\n",
    "    new_feature = []\n",
    "    for clasificador in clasif_list:\n",
    "        for a,b in kf.split(dataset):\n",
    "            clasificador.fit(dataset.iloc[a],labels.iloc[a])\n",
    "            new_labels = clasificador.predict_proba(dataset.iloc[b])[:,1]\n",
    "            new_feature.extend(new_labels)\n",
    "        newindex = len(new_dataset.columns)+1\n",
    "        new_dataset[newindex] = new_feature\n",
    "        to_return.append(newindex)\n",
    "    return new_dataset.loc[:,to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregarFeatureTrainCB (dataset,labels,clasif_list,n):\n",
    "    to_return = []\n",
    "    new_dataset = dataset.copy(deep=True)\n",
    "    kf = KFold(n_splits=n)\n",
    "    new_feature = []\n",
    "    for clasificador in clasif_list:\n",
    "        for a,b in kf.split(dataset):\n",
    "            clasificador.fit(dataset.iloc[a],labels.iloc[a],cat_features=cat)\n",
    "            new_labels = clasificador.predict_proba(dataset.iloc[b])[:,1]\n",
    "            new_feature.extend(new_labels)\n",
    "        newindex = len(new_dataset.columns)+1\n",
    "        new_dataset[newindex] = new_feature\n",
    "        to_return.append(newindex)\n",
    "    return new_dataset.loc[:,to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregarFeaturePredict(dataset,labels,predict,clasif_list):\n",
    "    to_return = []\n",
    "    new_predict = predict.copy(deep=True)\n",
    "    for classifier in clasif_list:\n",
    "        classifier.fit(dataset,labels)\n",
    "        prediction = classifier.predict_proba(predict)[:,1]\n",
    "        newindex = len(predict.columns)+1\n",
    "        new_predict[newindex] = prediction\n",
    "        to_return.append(newindex)\n",
    "    return new_predict.loc[:,to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregarFeaturePredictCB(dataset,labels,predict,clasif_list):\n",
    "    to_return = []\n",
    "    new_predict = predict.copy(deep=True)\n",
    "    for classifier in clasif_list:\n",
    "        classifier.fit(dataset,labels,cat_features=cat)\n",
    "        prediction = classifier.predict_proba(predict)[:,1]\n",
    "        newindex = len(predict.columns)+1\n",
    "        new_predict[newindex] = prediction\n",
    "        to_return.append(newindex)\n",
    "    return new_predict.loc[:,to_return]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgbmparams = {   }\n",
    "cb_classifier = cb.CatBoostClassifier(iterations=200,\n",
    "                                 depth=8,\n",
    "                                 l2_leaf_reg=50,\n",
    "                                 random_strength=0.1,\n",
    "                                 bagging_temperature=0,\n",
    "                                 border_count=128)\n",
    "xgb_classifier = xgb.XGBClassifier(colsample_bytree = 0.606653667095343,\n",
    "             gamma = 7,\n",
    "             learning_rate = 0.016238752458245277,\n",
    "             max_depth = 10,\n",
    "             min_child_weight = 5,\n",
    "             n_estimators = 346,\n",
    "             subsample = 0.7847190225361189)\n",
    "lgbm_classifier = lgb.LGBMClassifier(learning_rate = 0.06748371705664348,\n",
    "                 max_bin = 205,\n",
    "                 min_data_in_leaf = 481,\n",
    "                 n_estimators = 187,\n",
    "                 num_leaves = 956)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding (para xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = ce.TargetEncoder()\n",
    "encoded = enc.fit_transform(np.array(training_set),np.array(training_labels))\n",
    "encoded_p = enc.transform(np.array(prediction_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set1 = agregarFeatureTrain(encoded,training_labels,[xgb_classifier],4)\n",
    "predict_set1 = agregarFeaturePredict(encoded,training_labels,encoded_p,[xgb_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set2 = agregarFeatureTrain(training_set,training_labels,[lgbm_classifier],4)\n",
    "predict_set2 = agregarFeaturePredict(training_set,training_labels,prediction_set,[lgbm_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set3 = agregarFeatureTrainCB(training_set,training_labels,[cb_classifier],4)\n",
    "predict_set3 = agregarFeaturePredictCB(training_set,training_labels,prediction_set,[cb_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set2.columns = ['lgbm']\n",
    "train_set3.columns = ['catboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_set2.columns = ['lgbm']\n",
    "predict_set3.columns = ['catboost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armar stack (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_training = train_set2.join(train_set3)\n",
    "stacked_training['xgboost'] = list(train_set1[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm</th>\n",
       "      <th>catboost</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0566e9c1</th>\n",
       "      <td>0.031517</td>\n",
       "      <td>0.044850</td>\n",
       "      <td>0.056806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6ec7ee77</th>\n",
       "      <td>0.048258</td>\n",
       "      <td>0.062670</td>\n",
       "      <td>0.068039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abe7a2fb</th>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.023425</td>\n",
       "      <td>0.031733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34728364</th>\n",
       "      <td>0.312454</td>\n",
       "      <td>0.156923</td>\n",
       "      <td>0.341176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87ed62de</th>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>0.012972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgbm  catboost   xgboost\n",
       "person                                \n",
       "0566e9c1  0.031517  0.044850  0.056806\n",
       "6ec7ee77  0.048258  0.062670  0.068039\n",
       "abe7a2fb  0.046011  0.023425  0.031733\n",
       "34728364  0.312454  0.156923  0.341176\n",
       "87ed62de  0.017839  0.011140  0.012972"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armar stack (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_predict = predict_set2.join(predict_set3)\n",
    "stacked_predict['xgboost'] = list(predict_set1[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm</th>\n",
       "      <th>catboost</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.007319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0.012040</td>\n",
       "      <td>0.060722</td>\n",
       "      <td>0.032214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.012345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cccea85e</th>\n",
       "      <td>0.035064</td>\n",
       "      <td>0.052161</td>\n",
       "      <td>0.074387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4c8a8b93</th>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>0.024076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgbm  catboost   xgboost\n",
       "person                                \n",
       "4886f805  0.001365  0.007907  0.007319\n",
       "0297fc1e  0.012040  0.060722  0.032214\n",
       "2d681dd8  0.006546  0.016244  0.012345\n",
       "cccea85e  0.035064  0.052161  0.074387\n",
       "4c8a8b93  0.003504  0.024271  0.024076"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion final (Score: 0.85527)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labels de xgboost, catboost y lightgbm con Logistic Regression como modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_training.to_csv('preentrenados/training_logrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_predict.to_csv('preentrenados/predict_logrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(stacked_training,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8627505908628511"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,log.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(stacked_training,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = log.predict_proba(stacked_predict)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.copy(deep=True)\n",
    "submit['label'] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.set_index('person').to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando algunas features del dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = ['busco_productos', 'clickeo_ad', 'hizo_checkout', 'entro_desde_motor',\n",
    "       'hizo_conversion', 'filtro_busquedas', 'busco_marca', 'visito_sitio',\n",
    "       'hizo_lead', 'modelos_distintos', 'busquedas',\n",
    "       'clicks_en_ads', 'checkouts', 'entradas_desde_motor',\n",
    "       'listar_productos', 'listar_marca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = stacked_training.join(training_set.loc[:,fts])\n",
    "pred_f = stacked_predict.join(prediction_set.loc[:,fts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(train_f,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584317609192725"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,log.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(train_f,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prediction = log.predict_proba(pred_f)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.set_index('person').copy(deep=True)\n",
    "submit['label'] = n_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost con todas las features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "forxgboost = stacked_training.reset_index().join(encoded).set_index('person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(forxgboost,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8638913423827671"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,xgb_classifier.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego KNN y RandomForests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = pd.DataFrame(normalize(encoded,axis=0))\n",
    "normalized_p = pd.DataFrame(normalize(encoded_p,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=15,p=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_knn = agregarFeatureTrain(normalized,training_labels,[knn],4)\n",
    "predict_set_knn = agregarFeaturePredict(normalized,training_labels,normalized_p,[knn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_rf = agregarFeatureTrain(encoded,training_labels,[rf],4)\n",
    "predict_set_rf = agregarFeaturePredict(encoded,training_labels,encoded_p,[rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armo set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_features = train_set2.join(train_set3,how='left')\n",
    "stacked_features['knn'] = list(train_set_knn[46])\n",
    "stacked_features['rf'] = list(train_set_rf[46])\n",
    "stacked_features['xgboost'] = list(train_set1[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_features_p = predict_set2.join(predict_set3,how='left')\n",
    "stacked_features_p['knn'] = list(predict_set_knn[46])\n",
    "stacked_features_p['rf'] = list(predict_set_rf[46])\n",
    "stacked_features_p['xgboost'] = list(predict_set1[46])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javif\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(stacked_features,labels['label'],train_size=0.9,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.860789117435889"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,log.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(stacked_features,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = log.predict_proba(stacked_features_p)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.copy(deep=True)\n",
    "submit['label'] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.set_index('person').to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost con de todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'n_estimators':stats.randint(150,500),\n",
    "    'learning_rate':stats.uniform(0.01,0.3),\n",
    "    'subsample':stats.uniform(0.3,0.7),\n",
    "    'min_child_weight':[1,5,10],\n",
    "    'max_depth':[3,10,6],\n",
    "    'gamma':stats.randint(0,10),\n",
    "    'colsample_bytree':stats.uniform(0.4,0.6)\n",
    "}\n",
    "grid = RandomizedSearchCV(xgb.XGBClassifier(n_jobs=-1),\n",
    "                          param_distributions=params,\n",
    "                          scoring='roc_auc',\n",
    "                          cv=2,\n",
    "                          verbose=1,\n",
    "                          n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "forxgboost2 = stacked_features.reset_index().join(encoded).set_index('person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost2predict = stacked_features_p.reset_index().join(encoded_p).set_index('person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(forxgboost2,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed: 27.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8609554080566848"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,grid.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5507688588435546, gamma=8,\n",
       "       learning_rate=0.02746639067303843, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=181, n_jobs=-1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.838043777420667)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.fit(forxgboost2,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.copy(deep=True).set_index('person')\n",
    "submit['label'] = grid.best_estimator_.predict_proba(xgboost2predict)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression tuneando parametros (score: 0.85527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "params = {\n",
    "    'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "}\n",
    "log = RandomizedSearchCV(logreg,param_distributions=params,verbose=0,cv=4,n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_training.to_csv('preentrenados/training_logrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_predict.to_csv('preentrenados/predict_logrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(stacked_training,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8681777303642428"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,log.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.best_estimator_.fit(stacked_training,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = log.best_estimator_.predict_proba(stacked_predict)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.copy(deep=True)\n",
    "submit['label'] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.set_index('person').to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
