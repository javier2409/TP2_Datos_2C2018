{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train y predict set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_04 = pd.read_csv('features_06.csv')\n",
    "features_04 = features_04.drop(['Unknown','Unknown.1'],axis=1)\n",
    "labels = pd.read_csv('labels_training_set.csv')\n",
    "kaggle = pd.read_csv('trocafone_kaggle_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = labels.set_index('person').join(features_04.set_index('person'),how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training.drop('label',axis=1)\n",
    "training_labels = training['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set = kaggle.set_index('person').join(features_04.set_index('person'),how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "catnames = []\n",
    "for index,v in enumerate(training_set.columns):\n",
    "    if training_set[v].dtype.name == 'object':\n",
    "        cat.append(index)\n",
    "        catnames.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in catnames:\n",
    "    training_set[i] = training_set[i].astype('category')\n",
    "    prediction_set[i] = prediction_set[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregarFeatureTrain (dataset,labels,clasif_list,n):\n",
    "    to_return = []\n",
    "    new_dataset = dataset.copy(deep=True)\n",
    "    kf = KFold(n_splits=n)\n",
    "    new_feature = []\n",
    "    for clasificador in clasif_list:\n",
    "        for a,b in kf.split(dataset):\n",
    "            clasificador.fit(dataset.iloc[a],labels.iloc[a])\n",
    "            new_labels = clasificador.predict_proba(dataset.iloc[b])[:,1]\n",
    "            new_feature.extend(new_labels)\n",
    "        newindex = len(new_dataset.columns)+1\n",
    "        new_dataset[newindex] = new_feature\n",
    "        to_return.append(newindex)\n",
    "    return new_dataset.loc[:,to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregarFeatureTrainCB (dataset,labels,clasif_list,n):\n",
    "    to_return = []\n",
    "    new_dataset = dataset.copy(deep=True)\n",
    "    kf = KFold(n_splits=n)\n",
    "    new_feature = []\n",
    "    for clasificador in clasif_list:\n",
    "        for a,b in kf.split(dataset):\n",
    "            clasificador.fit(dataset.iloc[a],labels.iloc[a],cat_features=cat,verbose=0)\n",
    "            new_labels = clasificador.predict_proba(dataset.iloc[b])[:,1]\n",
    "            new_feature.extend(new_labels)\n",
    "        newindex = len(new_dataset.columns)+1\n",
    "        new_dataset[newindex] = new_feature\n",
    "        to_return.append(newindex)\n",
    "    return new_dataset.loc[:,to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregarFeaturePredict(dataset,labels,predict,clasif_list):\n",
    "    to_return = []\n",
    "    new_predict = predict.copy(deep=True)\n",
    "    for classifier in clasif_list:\n",
    "        classifier.fit(dataset,labels)\n",
    "        prediction = classifier.predict_proba(predict)[:,1]\n",
    "        newindex = len(predict.columns)+1\n",
    "        new_predict[newindex] = prediction\n",
    "        to_return.append(newindex)\n",
    "    return new_predict.loc[:,to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregarFeaturePredictCB(dataset,labels,predict,clasif_list):\n",
    "    to_return = []\n",
    "    new_predict = predict.copy(deep=True)\n",
    "    for classifier in clasif_list:\n",
    "        classifier.fit(dataset,labels,cat_features=cat,verbose=0)\n",
    "        prediction = classifier.predict_proba(predict)[:,1]\n",
    "        newindex = len(predict.columns)+1\n",
    "        new_predict[newindex] = prediction\n",
    "        to_return.append(newindex)\n",
    "    return new_predict.loc[:,to_return]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgbmparams = {   }\n",
    "cb_classifier = cb.CatBoostClassifier(iterations=400,\n",
    "                                 depth=10,\n",
    "                                 l2_leaf_reg=50,\n",
    "                                 random_strength=0.1,\n",
    "                                 bagging_temperature=0,\n",
    "                                 border_count=128)\n",
    "xgb_classifier = xgb.XGBClassifier(colsample_bytree = 0.606653667095343,\n",
    "             gamma = 7,\n",
    "             learning_rate = 0.016238752458245277,\n",
    "             max_depth = 12,\n",
    "             min_child_weight = 5,\n",
    "             n_estimators = 346,\n",
    "             subsample = 0.7847190225361189)\n",
    "lgbm_classifier = lgb.LGBMClassifier(learning_rate = 0.06748371705664348,\n",
    "                 max_bin = 205,\n",
    "                 min_data_in_leaf = 481,\n",
    "                 n_estimators = 187,\n",
    "                 num_leaves = 956)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding (para xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = ce.TargetEncoder()\n",
    "encoded = enc.fit_transform(np.array(training_set),np.array(training_labels))\n",
    "encoded_p = enc.transform(np.array(prediction_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set1 = agregarFeatureTrain(encoded,training_labels,[xgb_classifier],2)\n",
    "predict_set1 = agregarFeaturePredict(encoded,training_labels,encoded_p,[xgb_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set2 = agregarFeatureTrain(training_set,training_labels,[lgbm_classifier],2)\n",
    "predict_set2 = agregarFeaturePredict(training_set,training_labels,prediction_set,[lgbm_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set3 = agregarFeatureTrainCB(training_set,training_labels,[cb_classifier],2)\n",
    "predict_set3 = agregarFeaturePredictCB(training_set,training_labels,prediction_set,[cb_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set2.columns = ['lgbm']\n",
    "train_set3.columns = ['catboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_set2.columns = ['lgbm']\n",
    "predict_set3.columns = ['catboost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armar stack (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_training = train_set2.join(train_set3)\n",
    "stacked_training['xgboost'] = list(train_set1[train_set1.columns[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm</th>\n",
       "      <th>catboost</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0566e9c1</th>\n",
       "      <td>0.104925</td>\n",
       "      <td>0.035126</td>\n",
       "      <td>0.060293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6ec7ee77</th>\n",
       "      <td>0.039298</td>\n",
       "      <td>0.049223</td>\n",
       "      <td>0.060477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abe7a2fb</th>\n",
       "      <td>0.051244</td>\n",
       "      <td>0.012723</td>\n",
       "      <td>0.030094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34728364</th>\n",
       "      <td>0.113891</td>\n",
       "      <td>0.134094</td>\n",
       "      <td>0.261684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87ed62de</th>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.010747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgbm  catboost   xgboost\n",
       "person                                \n",
       "0566e9c1  0.104925  0.035126  0.060293\n",
       "6ec7ee77  0.039298  0.049223  0.060477\n",
       "abe7a2fb  0.051244  0.012723  0.030094\n",
       "34728364  0.113891  0.134094  0.261684\n",
       "87ed62de  0.006360  0.006881  0.010747"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armar stack (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_predict = predict_set2.join(predict_set3)\n",
    "stacked_predict['xgboost'] = list(predict_set1[predict_set1.columns[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm</th>\n",
       "      <th>catboost</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4886f805</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.007877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0297fc1e</th>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.083819</td>\n",
       "      <td>0.043512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d681dd8</th>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>0.015421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cccea85e</th>\n",
       "      <td>0.037773</td>\n",
       "      <td>0.053141</td>\n",
       "      <td>0.102484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4c8a8b93</th>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.021630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgbm  catboost   xgboost\n",
       "person                                \n",
       "4886f805  0.000426  0.003111  0.007877\n",
       "0297fc1e  0.021861  0.083819  0.043512\n",
       "2d681dd8  0.005023  0.014274  0.015421\n",
       "cccea85e  0.037773  0.053141  0.102484\n",
       "4c8a8b93  0.002734  0.014094  0.021630"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion final (Score:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labels de xgboost, catboost y lightgbm con Logistic Regression como modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_training.to_csv('preentrenados/23_stacked_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_predict.to_csv('preentrenados/23_stacked_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(stacked_training,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668939118258074"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,log.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(stacked_training,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = log.predict_proba(stacked_predict)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.copy(deep=True)\n",
    "submit['label'] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.set_index('person').to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando algunas features del dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['viewed product', 'searched products', 'ad campaign hit', 'staticpage',\n",
       "       'checkout', 'search engine hit', 'conversion', 'generic listing',\n",
       "       'brand listing', 'visited site', 'lead1', 'Excelente', 'Muito Bom',\n",
       "       'Bom', 'Bom - Sem Touch ID', 'Novo', '32GB', '64GB', '128GB', '16GB',\n",
       "       '8GB', '256GB', '4GB', '512MB', 'Conditions', 'AboutUs', 'how-to-sell',\n",
       "       'trust-trocafone', 'how-to-buy', 'CustomerService', 'club-trocafone',\n",
       "       'Quiosks', 'FaqEcommerce', 'TermsAndConditionsReturnEcommerce',\n",
       "       'TermsAndConditionsEcommerce', 'galaxy-s8', 'PrivacyEcommerce',\n",
       "       'black_friday', 'Google', 'Yahoo', 'Bing', 'Ask', 'Smartphone',\n",
       "       'Computer', 'Tablet', 'Paid', 'Organic', 'Direct', 'Referral', 'Social',\n",
       "       'Email', 'mayor_evento', 'prod_visto', 'dispos', 'compras', 'visitas',\n",
       "       'cant_prod_vistos', 'cant_eventos', 'permanencia', 'hace_cuanto_visito',\n",
       "       'eventos_por_dia', 'channel', 'visitas_por_dia', 'vio_celulares',\n",
       "       'region', 'is_new', 'personas_mismo_prod_visto', 'opsis', 'scrnres',\n",
       "       'personas_mismo_mayor_evento', 'personas_mismo_disp',\n",
       "       'personas_mismo_region', 'personas_mismo_channel', 'primer_channel',\n",
       "       'lead', 'personas_mismo_opsis', 'personas_mismo_scrnres'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = ['viewed product', 'searched products', 'ad campaign hit', 'staticpage',\n",
    "       'checkout', 'search engine hit', 'conversion', 'generic listing',\n",
    "       'brand listing', 'visited site', 'lead1', 'Excelente', 'Muito Bom',\n",
    "       'Bom', 'Bom - Sem Touch ID', 'Novo', '32GB', '64GB', '128GB', '16GB',\n",
    "       '8GB', '256GB', '4GB', '512MB', 'Conditions', 'AboutUs', 'how-to-sell',\n",
    "       'trust-trocafone', 'how-to-buy', 'CustomerService', 'club-trocafone',\n",
    "       'Quiosks', 'FaqEcommerce', 'TermsAndConditionsReturnEcommerce',\n",
    "       'TermsAndConditionsEcommerce', 'galaxy-s8', 'PrivacyEcommerce',\n",
    "       'black_friday', 'Google', 'Yahoo', 'Bing', 'Ask', 'Smartphone',\n",
    "       'Computer', 'Tablet', 'Paid', 'Organic', 'Direct', 'Referral', 'Social',\n",
    "       'Email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = stacked_training.join(training_set.loc[:,fts])\n",
    "pred_f = stacked_predict.join(prediction_set.loc[:,fts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(train_f,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8497084310268147"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,log.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(train_f,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prediction = log.predict_proba(pred_f)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.set_index('person').copy(deep=True)\n",
    "submit['label'] = n_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost con todas las features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "forxgboost = stacked_training.reset_index().join(encoded).set_index('person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "forxgboost_p = stacked_predict.reset_index().join(encoded_p).set_index('person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(forxgboost,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8648361869672012"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,xgb_classifier.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.606653667095343, gamma=7,\n",
       "       learning_rate=0.016238752458245277, max_delta_step=0, max_depth=12,\n",
       "       min_child_weight=5, missing=None, n_estimators=346, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.7847190225361189)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier.fit(forxgboost,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_classifier.predict_proba(forxgboost_p)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.set_index('person')\n",
    "submit['label'] = pred\n",
    "submit.to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego KNN y RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = pd.DataFrame(normalize(encoded,axis=0))\n",
    "normalized_p = pd.DataFrame(normalize(encoded_p,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=15,p=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_knn = agregarFeatureTrain(normalized,training_labels,[knn],4)\n",
    "predict_set_knn = agregarFeaturePredict(normalized,training_labels,normalized_p,[knn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_rf = agregarFeatureTrain(encoded,training_labels,[rf],4)\n",
    "predict_set_rf = agregarFeaturePredict(encoded,training_labels,encoded_p,[rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armo set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_features = train_set2.join(train_set3,how='left')\n",
    "stacked_features['knn'] = list(train_set_knn[46])\n",
    "stacked_features['rf'] = list(train_set_rf[46])\n",
    "stacked_features['xgboost'] = list(train_set1[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_features_p = predict_set2.join(predict_set3,how='left')\n",
    "stacked_features_p['knn'] = list(predict_set_knn[46])\n",
    "stacked_features_p['rf'] = list(predict_set_rf[46])\n",
    "stacked_features_p['xgboost'] = list(predict_set1[46])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javif\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(stacked_features,labels['label'],train_size=0.9,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.860789117435889"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,log.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(stacked_features,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = log.predict_proba(stacked_features_p)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.copy(deep=True)\n",
    "submit['label'] = final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression tuneando parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "params = {\n",
    "    'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "}\n",
    "log = RandomizedSearchCV(logreg,param_distributions=params,verbose=0,cv=4,n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(stacked_training,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8767335911186463"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(xtrain,ytrain)\n",
    "roc_auc_score(ytest,log.predict_proba(xtest)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.best_estimator_.fit(stacked_training,labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = log.best_estimator_.predict_proba(stacked_predict)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = kaggle.copy(deep=True)\n",
    "submit['label'] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.set_index('person').to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
